{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec不需要标签即可创建有意义的表示形式。\n",
    "# 运用于情感分析\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 评论到单词列表清洗函数\n",
    "def review_to_wordlist( review, remove_stopwords=False ):\n",
    "    # Function:将文档转换为单词序列\n",
    "    # 返回一个单词list\n",
    "    # 是否删除stop words为可选项\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #  \n",
    "    # 2. 删除标点符号\n",
    "    # 保存数字\n",
    "    review_text = re.sub(\"[^a-zA-Z0-9]\",\" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. 返回一个单词list\n",
    "    return(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec期望输入是单个句子，每个句子作为单词列表。换句话说，输入格式是列表的列表。\n",
    "# 将使用NLTK的punkt标记器进行句子拆分\n",
    "\n",
    "import nltk.data\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "# 将完整的评论拆分成句子\n",
    "def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a review into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. 用NLTK将段落分成句子\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "#     print(len(raw_sentences))\n",
    "#     print(len(raw_sentences[0]))\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # 跳过空句子\n",
    "        if len(raw_sentence) > 0:\n",
    "            # 对分好的句子分词\n",
    "            sentences.append( review_to_wordlist( raw_sentence, remove_stopwords=False ))\n",
    "    #\n",
    "    # 返回一个句子列表sentences，且每个sentence是一个单词list。\n",
    "    # 即返回一个元素为列表的列表\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 25000 labeled train reviews, 25000 labeled test reviews, and 50000 unlabeled reviews\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 读取数据 \n",
    "train = pd.read_csv( \"F:\\\\NLP\\\\kaggle_data\\\\labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )\n",
    "test = pd.read_csv( \"F:\\\\NLP\\\\kaggle_data\\\\testData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )\n",
    "unlabeled_train = pd.read_csv( \"F:\\\\NLP\\\\kaggle_data\\\\unlabeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )\n",
    "\n",
    "# 共读取100000条数据\n",
    "print(\"Read %d labeled train reviews, %d labeled test reviews, \"\n",
    " \"and %d unlabeled reviews\\n\" % (train[\"review\"].size,  \n",
    " test[\"review\"].size, unlabeled_train[\"review\"].size ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train[\"review\"][0])\n",
    "temp = review_to_sentences(train[\"review\"][0], tokenizer)\n",
    "# print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:333: MarkupResemblesLocatorWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:333: MarkupResemblesLocatorWarning: \"...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:421: MarkupResemblesLocatorWarning: \"http://www.happierabroad.com\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from unlabeled set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:421: MarkupResemblesLocatorWarning: \"http://www.archive.org/details/LovefromaStranger\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:421: MarkupResemblesLocatorWarning: \"http://www.loosechangeguide.com/LooseChangeGuide.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:333: MarkupResemblesLocatorWarning: \"... ...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:333: MarkupResemblesLocatorWarning: \"....\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:421: MarkupResemblesLocatorWarning: \"http://www.msnbc.msn.com/id/4972055/site/newsweek/\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:333: MarkupResemblesLocatorWarning: \"..\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:421: MarkupResemblesLocatorWarning: \"http://www.youtube.com/watch?v=a0KSqelmgN8\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:333: MarkupResemblesLocatorWarning: \".. .\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:421: MarkupResemblesLocatorWarning: \"http://jake-weird.blogspot.com/2007/08/beneath.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "795538\n",
      "['with', 'all', 'this', 'stuff', 'going', 'down', 'at', 'the', 'moment', 'with', 'mj', 'i', 've', 'started', 'listening', 'to', 'his', 'music', 'watching', 'the', 'odd', 'documentary', 'here', 'and', 'there', 'watched', 'the', 'wiz', 'and', 'watched', 'moonwalker', 'again']\n",
      "['pathmark', 'means', 'savings']\n"
     ]
    }
   ],
   "source": [
    "# 初始化空句子列表sentences\n",
    "sentences = []\n",
    "# 加载punkt标记生成器\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "# +=和append的区别，大部分时候相同，但此处不同\n",
    "# 如果要将列表列表追加到另一个列表列表，则“ append”将仅追加第一个列表；\n",
    "# 您需要使用“ + =”才能一次加入所有列表。\n",
    "print(\"Parsing sentences from training set\")\n",
    "for review in train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "\n",
    "print(\"Parsing sentences from unlabeled set\")\n",
    "for review in unlabeled_train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "\n",
    "# 打印句子总数和输出样例\n",
    "print(len(sentences))\n",
    "print(sentences[0])\n",
    "print(sentences[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word2vec模型\n",
    "\n",
    "1.体系结构：体系结构选项是跳跃语法（默认）或连续的单词袋。我们发现，skip-gram的速度稍慢一些，但产生了更好的结果。\n",
    "\n",
    "2.训练算法：分层softmax（默认）或负采样。对于我们来说，默认设置效果很好。\n",
    "常用词的下采样：Google文档建议使用.00001和.001之间的值。对于我们来说，更接近0.001的值似乎可以提高最终模型的准确性。\n",
    "\n",
    "3.字向量维数：更多功能会导致更长的运行时间，并且通常（但并非总是）会导致更好的模型。合理的值可以在几十到几百之间。我们用了300。\n",
    "上下文/窗口大小：训练算法应考虑多少个上下文词？10对于分层softmax似乎很好用（越多越好，直到一定程度）。\n",
    "\n",
    "4.辅助线程：要运行的并行进程数。这是特定于计算机的，但是在大多数系统上应该在4到6之间工作。\n",
    "\n",
    "5.最小单词数：这有助于将词汇量限制为有意义的单词。在所有文档中至少出现多次的任何单词都将被忽略。合理的值应该在10到100之间。在这种情况下，由于每部电影出现30次，因此我们将最小字数设置为40，以避免过于重视单个电影标题。这样一来，整个词汇量约为15,000个单词。较高的值也有助于限制运行时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 导入内置日志记录模块并配置，使word2Vec创建的输出消息更好\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',level=logging.INFO)\n",
    "\n",
    "# 设置参数值\n",
    "num_features = 300    # 词向量的维数                      \n",
    "min_word_count = 40   # 最小单词数                        \n",
    "num_workers = 6       # 并行线程数\n",
    "context = 10          # 上下文窗口大小                                                                                    \n",
    "downsampling = 1e-3   # 常用词下采样设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-28 22:49:59,161 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "# 导入word2vec\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-28 22:50:45,459 : INFO : collecting all words and their counts\n",
      "2020-09-28 22:50:45,460 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-09-28 22:50:45,515 : INFO : PROGRESS: at sentence #10000, processed 227240 words, keeping 18038 word types\n",
      "2020-09-28 22:50:45,569 : INFO : PROGRESS: at sentence #20000, processed 454577 words, keeping 25324 word types\n",
      "2020-09-28 22:50:45,621 : INFO : PROGRESS: at sentence #30000, processed 675274 words, keeping 30478 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-28 22:50:45,674 : INFO : PROGRESS: at sentence #40000, processed 903014 words, keeping 34863 word types\n",
      "2020-09-28 22:50:45,730 : INFO : PROGRESS: at sentence #50000, processed 1123503 words, keeping 38329 word types\n",
      "2020-09-28 22:50:45,797 : INFO : PROGRESS: at sentence #60000, processed 1346264 words, keeping 41338 word types\n",
      "2020-09-28 22:50:45,868 : INFO : PROGRESS: at sentence #70000, processed 1570738 words, keeping 43986 word types\n",
      "2020-09-28 22:50:45,936 : INFO : PROGRESS: at sentence #80000, processed 1791248 words, keeping 46400 word types\n",
      "2020-09-28 22:50:46,005 : INFO : PROGRESS: at sentence #90000, processed 2016722 words, keeping 48869 word types\n",
      "2020-09-28 22:50:46,065 : INFO : PROGRESS: at sentence #100000, processed 2239896 words, keeping 50980 word types\n",
      "2020-09-28 22:50:46,126 : INFO : PROGRESS: at sentence #110000, processed 2460901 words, keeping 52890 word types\n",
      "2020-09-28 22:50:46,180 : INFO : PROGRESS: at sentence #120000, processed 2684304 words, keeping 54967 word types\n",
      "2020-09-28 22:50:46,233 : INFO : PROGRESS: at sentence #130000, processed 2911246 words, keeping 56741 word types\n",
      "2020-09-28 22:50:46,287 : INFO : PROGRESS: at sentence #140000, processed 3125257 words, keeping 58290 word types\n",
      "2020-09-28 22:50:46,344 : INFO : PROGRESS: at sentence #150000, processed 3352187 words, keeping 60038 word types\n",
      "2020-09-28 22:50:46,398 : INFO : PROGRESS: at sentence #160000, processed 3576077 words, keeping 61632 word types\n",
      "2020-09-28 22:50:46,454 : INFO : PROGRESS: at sentence #170000, processed 3800671 words, keeping 63128 word types\n",
      "2020-09-28 22:50:46,508 : INFO : PROGRESS: at sentence #180000, processed 4022558 words, keeping 64575 word types\n",
      "2020-09-28 22:50:46,563 : INFO : PROGRESS: at sentence #190000, processed 4249063 words, keeping 65900 word types\n",
      "2020-09-28 22:50:46,618 : INFO : PROGRESS: at sentence #200000, processed 4474464 words, keeping 67217 word types\n",
      "2020-09-28 22:50:46,674 : INFO : PROGRESS: at sentence #210000, processed 4697223 words, keeping 68546 word types\n",
      "2020-09-28 22:50:46,733 : INFO : PROGRESS: at sentence #220000, processed 4923567 words, keeping 69884 word types\n",
      "2020-09-28 22:50:46,790 : INFO : PROGRESS: at sentence #230000, processed 5147438 words, keeping 71164 word types\n",
      "2020-09-28 22:50:46,849 : INFO : PROGRESS: at sentence #240000, processed 5376271 words, keeping 72402 word types\n",
      "2020-09-28 22:50:46,909 : INFO : PROGRESS: at sentence #250000, processed 5591639 words, keeping 73620 word types\n",
      "2020-09-28 22:50:46,970 : INFO : PROGRESS: at sentence #260000, processed 5812902 words, keeping 74778 word types\n",
      "2020-09-28 22:50:47,037 : INFO : PROGRESS: at sentence #270000, processed 6035539 words, keeping 76111 word types\n",
      "2020-09-28 22:50:47,114 : INFO : PROGRESS: at sentence #280000, processed 6262673 words, keeping 77737 word types\n",
      "2020-09-28 22:50:47,182 : INFO : PROGRESS: at sentence #290000, processed 6487100 words, keeping 79229 word types\n",
      "2020-09-28 22:50:47,243 : INFO : PROGRESS: at sentence #300000, processed 6713050 words, keeping 80594 word types\n",
      "2020-09-28 22:50:47,299 : INFO : PROGRESS: at sentence #310000, processed 6939617 words, keeping 81947 word types\n",
      "2020-09-28 22:50:47,356 : INFO : PROGRESS: at sentence #320000, processed 7165784 words, keeping 83307 word types\n",
      "2020-09-28 22:50:47,412 : INFO : PROGRESS: at sentence #330000, processed 7388850 words, keeping 84568 word types\n",
      "2020-09-28 22:50:47,474 : INFO : PROGRESS: at sentence #340000, processed 7619626 words, keeping 85844 word types\n",
      "2020-09-28 22:50:47,532 : INFO : PROGRESS: at sentence #350000, processed 7844225 words, keeping 87024 word types\n",
      "2020-09-28 22:50:47,594 : INFO : PROGRESS: at sentence #360000, processed 8066077 words, keeping 88224 word types\n",
      "2020-09-28 22:50:47,649 : INFO : PROGRESS: at sentence #370000, processed 8294502 words, keeping 89358 word types\n",
      "2020-09-28 22:50:47,707 : INFO : PROGRESS: at sentence #380000, processed 8520969 words, keeping 90551 word types\n",
      "2020-09-28 22:50:47,768 : INFO : PROGRESS: at sentence #390000, processed 8752087 words, keeping 91609 word types\n",
      "2020-09-28 22:50:47,826 : INFO : PROGRESS: at sentence #400000, processed 8976320 words, keeping 92659 word types\n",
      "2020-09-28 22:50:47,883 : INFO : PROGRESS: at sentence #410000, processed 9198945 words, keeping 93646 word types\n",
      "2020-09-28 22:50:47,939 : INFO : PROGRESS: at sentence #420000, processed 9421335 words, keeping 94699 word types\n",
      "2020-09-28 22:50:47,995 : INFO : PROGRESS: at sentence #430000, processed 9650286 words, keeping 95740 word types\n",
      "2020-09-28 22:50:48,052 : INFO : PROGRESS: at sentence #440000, processed 9878400 words, keeping 96739 word types\n",
      "2020-09-28 22:50:48,112 : INFO : PROGRESS: at sentence #450000, processed 10103393 words, keeping 97893 word types\n",
      "2020-09-28 22:50:48,169 : INFO : PROGRESS: at sentence #460000, processed 10337523 words, keeping 98968 word types\n",
      "2020-09-28 22:50:48,225 : INFO : PROGRESS: at sentence #470000, processed 10566707 words, keeping 99845 word types\n",
      "2020-09-28 22:50:48,281 : INFO : PROGRESS: at sentence #480000, processed 10788353 words, keeping 100796 word types\n",
      "2020-09-28 22:50:48,339 : INFO : PROGRESS: at sentence #490000, processed 11016516 words, keeping 101878 word types\n",
      "2020-09-28 22:50:48,395 : INFO : PROGRESS: at sentence #500000, processed 11239492 words, keeping 102801 word types\n",
      "2020-09-28 22:50:48,452 : INFO : PROGRESS: at sentence #510000, processed 11466075 words, keeping 103750 word types\n",
      "2020-09-28 22:50:48,509 : INFO : PROGRESS: at sentence #520000, processed 11690799 words, keeping 104669 word types\n",
      "2020-09-28 22:50:48,563 : INFO : PROGRESS: at sentence #530000, processed 11916527 words, keeping 105502 word types\n",
      "2020-09-28 22:50:48,618 : INFO : PROGRESS: at sentence #540000, processed 12142510 words, keeping 106401 word types\n",
      "2020-09-28 22:50:48,675 : INFO : PROGRESS: at sentence #550000, processed 12369376 words, keeping 107290 word types\n",
      "2020-09-28 22:50:48,732 : INFO : PROGRESS: at sentence #560000, processed 12591947 words, keeping 108175 word types\n",
      "2020-09-28 22:50:48,797 : INFO : PROGRESS: at sentence #570000, processed 12822406 words, keeping 108982 word types\n",
      "2020-09-28 22:50:48,853 : INFO : PROGRESS: at sentence #580000, processed 13045171 words, keeping 109872 word types\n",
      "2020-09-28 22:50:48,913 : INFO : PROGRESS: at sentence #590000, processed 13271905 words, keeping 110744 word types\n",
      "2020-09-28 22:50:48,971 : INFO : PROGRESS: at sentence #600000, processed 13495426 words, keeping 111495 word types\n",
      "2020-09-28 22:50:49,030 : INFO : PROGRESS: at sentence #610000, processed 13717726 words, keeping 112397 word types\n",
      "2020-09-28 22:50:49,087 : INFO : PROGRESS: at sentence #620000, processed 13945488 words, keeping 113171 word types\n",
      "2020-09-28 22:50:49,145 : INFO : PROGRESS: at sentence #630000, processed 14171064 words, keeping 113970 word types\n",
      "2020-09-28 22:50:49,199 : INFO : PROGRESS: at sentence #640000, processed 14393088 words, keeping 114810 word types\n",
      "2020-09-28 22:50:49,254 : INFO : PROGRESS: at sentence #650000, processed 14620290 words, keeping 115619 word types\n",
      "2020-09-28 22:50:49,311 : INFO : PROGRESS: at sentence #660000, processed 14844358 words, keeping 116395 word types\n",
      "2020-09-28 22:50:49,366 : INFO : PROGRESS: at sentence #670000, processed 15069027 words, keeping 117116 word types\n",
      "2020-09-28 22:50:49,423 : INFO : PROGRESS: at sentence #680000, processed 15295190 words, keeping 117841 word types\n",
      "2020-09-28 22:50:49,478 : INFO : PROGRESS: at sentence #690000, processed 15518608 words, keeping 118638 word types\n",
      "2020-09-28 22:50:49,535 : INFO : PROGRESS: at sentence #700000, processed 15748536 words, keeping 119469 word types\n",
      "2020-09-28 22:50:49,596 : INFO : PROGRESS: at sentence #710000, processed 15972819 words, keeping 120131 word types\n",
      "2020-09-28 22:50:49,654 : INFO : PROGRESS: at sentence #720000, processed 16199405 words, keeping 120766 word types\n",
      "2020-09-28 22:50:49,715 : INFO : PROGRESS: at sentence #730000, processed 16427036 words, keeping 121514 word types\n",
      "2020-09-28 22:50:49,769 : INFO : PROGRESS: at sentence #740000, processed 16649412 words, keeping 122243 word types\n",
      "2020-09-28 22:50:49,827 : INFO : PROGRESS: at sentence #750000, processed 16869072 words, keeping 122893 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-28 22:50:49,881 : INFO : PROGRESS: at sentence #760000, processed 17089761 words, keeping 123539 word types\n",
      "2020-09-28 22:50:49,939 : INFO : PROGRESS: at sentence #770000, processed 17318248 words, keeping 124326 word types\n",
      "2020-09-28 22:50:50,000 : INFO : PROGRESS: at sentence #780000, processed 17549751 words, keeping 125052 word types\n",
      "2020-09-28 22:50:50,064 : INFO : PROGRESS: at sentence #790000, processed 17778071 words, keeping 125740 word types\n",
      "2020-09-28 22:50:50,102 : INFO : collected 126187 word types from a corpus of 17901873 raw words and 795538 sentences\n",
      "2020-09-28 22:50:50,103 : INFO : Loading a fresh vocabulary\n",
      "2020-09-28 22:50:50,190 : INFO : effective_min_count=40 retains 16731 unique words (13% of original 126187, drops 109456)\n",
      "2020-09-28 22:50:50,191 : INFO : effective_min_count=40 leaves 17335707 word corpus (96% of original 17901873, drops 566166)\n",
      "2020-09-28 22:50:50,254 : INFO : deleting the raw counts dictionary of 126187 items\n",
      "2020-09-28 22:50:50,259 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2020-09-28 22:50:50,260 : INFO : downsampling leaves estimated 12862859 word corpus (74.2% of prior 17335707)\n",
      "2020-09-28 22:50:50,334 : INFO : estimated required memory for 16731 words and 300 dimensions: 48519900 bytes\n",
      "2020-09-28 22:50:50,336 : INFO : resetting layer weights\n",
      "2020-09-28 22:50:54,790 : INFO : training model with 6 workers on 16731 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2020-09-28 22:50:55,817 : INFO : EPOCH 1 - PROGRESS: at 6.97% examples, 891046 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:50:56,839 : INFO : EPOCH 1 - PROGRESS: at 14.13% examples, 891629 words/s, in_qsize 12, out_qsize 0\n",
      "2020-09-28 22:50:57,845 : INFO : EPOCH 1 - PROGRESS: at 21.44% examples, 903577 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:50:58,854 : INFO : EPOCH 1 - PROGRESS: at 28.32% examples, 895891 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:50:59,857 : INFO : EPOCH 1 - PROGRESS: at 35.51% examples, 899475 words/s, in_qsize 12, out_qsize 2\n",
      "2020-09-28 22:51:00,858 : INFO : EPOCH 1 - PROGRESS: at 41.48% examples, 877636 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:01,876 : INFO : EPOCH 1 - PROGRESS: at 48.65% examples, 883217 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:02,880 : INFO : EPOCH 1 - PROGRESS: at 55.89% examples, 888768 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:03,892 : INFO : EPOCH 1 - PROGRESS: at 62.57% examples, 885284 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:04,915 : INFO : EPOCH 1 - PROGRESS: at 70.42% examples, 895774 words/s, in_qsize 10, out_qsize 1\n",
      "2020-09-28 22:51:05,921 : INFO : EPOCH 1 - PROGRESS: at 77.93% examples, 901818 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:06,932 : INFO : EPOCH 1 - PROGRESS: at 84.56% examples, 897089 words/s, in_qsize 10, out_qsize 1\n",
      "2020-09-28 22:51:07,941 : INFO : EPOCH 1 - PROGRESS: at 91.28% examples, 894311 words/s, in_qsize 12, out_qsize 0\n",
      "2020-09-28 22:51:08,948 : INFO : EPOCH 1 - PROGRESS: at 98.09% examples, 892444 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:09,175 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-09-28 22:51:09,186 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-09-28 22:51:09,187 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-09-28 22:51:09,189 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-28 22:51:09,191 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-28 22:51:09,206 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-28 22:51:09,207 : INFO : EPOCH - 1 : training on 17901873 raw words (12863311 effective words) took 14.4s, 893588 effective words/s\n",
      "2020-09-28 22:51:10,221 : INFO : EPOCH 2 - PROGRESS: at 5.28% examples, 680004 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:11,222 : INFO : EPOCH 2 - PROGRESS: at 12.60% examples, 805536 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:12,230 : INFO : EPOCH 2 - PROGRESS: at 19.93% examples, 845203 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:13,241 : INFO : EPOCH 2 - PROGRESS: at 26.69% examples, 848837 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:14,246 : INFO : EPOCH 2 - PROGRESS: at 34.25% examples, 869965 words/s, in_qsize 12, out_qsize 0\n",
      "2020-09-28 22:51:15,259 : INFO : EPOCH 2 - PROGRESS: at 40.85% examples, 865538 words/s, in_qsize 10, out_qsize 1\n",
      "2020-09-28 22:51:16,269 : INFO : EPOCH 2 - PROGRESS: at 48.37% examples, 879822 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:17,269 : INFO : EPOCH 2 - PROGRESS: at 55.78% examples, 888966 words/s, in_qsize 10, out_qsize 1\n",
      "2020-09-28 22:51:18,270 : INFO : EPOCH 2 - PROGRESS: at 63.29% examples, 898386 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:19,289 : INFO : EPOCH 2 - PROGRESS: at 70.42% examples, 898744 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:20,306 : INFO : EPOCH 2 - PROGRESS: at 76.55% examples, 887422 words/s, in_qsize 10, out_qsize 1\n",
      "2020-09-28 22:51:21,326 : INFO : EPOCH 2 - PROGRESS: at 83.80% examples, 889761 words/s, in_qsize 12, out_qsize 1\n",
      "2020-09-28 22:51:22,327 : INFO : EPOCH 2 - PROGRESS: at 91.28% examples, 895606 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:23,333 : INFO : EPOCH 2 - PROGRESS: at 98.43% examples, 896856 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:23,509 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-09-28 22:51:23,511 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-09-28 22:51:23,531 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-09-28 22:51:23,533 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-28 22:51:23,535 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-28 22:51:23,541 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-28 22:51:23,543 : INFO : EPOCH - 2 : training on 17901873 raw words (12863153 effective words) took 14.3s, 897951 effective words/s\n",
      "2020-09-28 22:51:24,563 : INFO : EPOCH 3 - PROGRESS: at 6.81% examples, 871727 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:25,568 : INFO : EPOCH 3 - PROGRESS: at 13.91% examples, 885620 words/s, in_qsize 12, out_qsize 1\n",
      "2020-09-28 22:51:26,591 : INFO : EPOCH 3 - PROGRESS: at 21.56% examples, 908613 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:27,592 : INFO : EPOCH 3 - PROGRESS: at 28.76% examples, 912461 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:28,594 : INFO : EPOCH 3 - PROGRESS: at 36.02% examples, 914263 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:29,600 : INFO : EPOCH 3 - PROGRESS: at 43.72% examples, 927143 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:30,600 : INFO : EPOCH 3 - PROGRESS: at 50.61% examples, 921717 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:31,601 : INFO : EPOCH 3 - PROGRESS: at 57.95% examples, 925522 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:32,622 : INFO : EPOCH 3 - PROGRESS: at 65.02% examples, 921674 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:33,623 : INFO : EPOCH 3 - PROGRESS: at 72.69% examples, 928357 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:34,629 : INFO : EPOCH 3 - PROGRESS: at 80.51% examples, 934694 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:35,630 : INFO : EPOCH 3 - PROGRESS: at 88.12% examples, 938629 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:36,637 : INFO : EPOCH 3 - PROGRESS: at 94.49% examples, 928884 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:37,398 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-09-28 22:51:37,410 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-09-28 22:51:37,411 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-09-28 22:51:37,419 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-28 22:51:37,421 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-28 22:51:37,423 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-28 22:51:37,425 : INFO : EPOCH - 3 : training on 17901873 raw words (12860777 effective words) took 13.9s, 927604 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-28 22:51:38,439 : INFO : EPOCH 4 - PROGRESS: at 7.20% examples, 920295 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:39,456 : INFO : EPOCH 4 - PROGRESS: at 14.69% examples, 929492 words/s, in_qsize 7, out_qsize 0\n",
      "2020-09-28 22:51:40,478 : INFO : EPOCH 4 - PROGRESS: at 20.71% examples, 869355 words/s, in_qsize 10, out_qsize 1\n",
      "2020-09-28 22:51:41,484 : INFO : EPOCH 4 - PROGRESS: at 27.21% examples, 859034 words/s, in_qsize 10, out_qsize 1\n",
      "2020-09-28 22:51:42,495 : INFO : EPOCH 4 - PROGRESS: at 34.89% examples, 881516 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:43,496 : INFO : EPOCH 4 - PROGRESS: at 42.22% examples, 892167 words/s, in_qsize 12, out_qsize 0\n",
      "2020-09-28 22:51:44,502 : INFO : EPOCH 4 - PROGRESS: at 49.65% examples, 901008 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:45,515 : INFO : EPOCH 4 - PROGRESS: at 57.15% examples, 907834 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:46,521 : INFO : EPOCH 4 - PROGRESS: at 64.35% examples, 910007 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:47,542 : INFO : EPOCH 4 - PROGRESS: at 71.74% examples, 912565 words/s, in_qsize 12, out_qsize 0\n",
      "2020-09-28 22:51:48,543 : INFO : EPOCH 4 - PROGRESS: at 79.22% examples, 916910 words/s, in_qsize 10, out_qsize 1\n",
      "2020-09-28 22:51:49,549 : INFO : EPOCH 4 - PROGRESS: at 86.75% examples, 920647 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:50,551 : INFO : EPOCH 4 - PROGRESS: at 93.18% examples, 913687 words/s, in_qsize 10, out_qsize 1\n",
      "2020-09-28 22:51:51,460 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-09-28 22:51:51,464 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-09-28 22:51:51,466 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-09-28 22:51:51,471 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-28 22:51:51,485 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-28 22:51:51,488 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-28 22:51:51,490 : INFO : EPOCH - 4 : training on 17901873 raw words (12864014 effective words) took 14.1s, 915220 effective words/s\n",
      "2020-09-28 22:51:52,511 : INFO : EPOCH 5 - PROGRESS: at 6.64% examples, 843315 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:53,521 : INFO : EPOCH 5 - PROGRESS: at 13.85% examples, 876406 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:54,523 : INFO : EPOCH 5 - PROGRESS: at 21.50% examples, 908453 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:55,537 : INFO : EPOCH 5 - PROGRESS: at 29.31% examples, 928891 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:56,553 : INFO : EPOCH 5 - PROGRESS: at 36.91% examples, 933505 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:57,553 : INFO : EPOCH 5 - PROGRESS: at 43.95% examples, 929810 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:51:58,574 : INFO : EPOCH 5 - PROGRESS: at 50.72% examples, 919318 words/s, in_qsize 12, out_qsize 1\n",
      "2020-09-28 22:51:59,576 : INFO : EPOCH 5 - PROGRESS: at 57.78% examples, 918729 words/s, in_qsize 9, out_qsize 2\n",
      "2020-09-28 22:52:00,581 : INFO : EPOCH 5 - PROGRESS: at 62.90% examples, 889846 words/s, in_qsize 12, out_qsize 1\n",
      "2020-09-28 22:52:01,582 : INFO : EPOCH 5 - PROGRESS: at 69.30% examples, 883351 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:52:02,615 : INFO : EPOCH 5 - PROGRESS: at 76.44% examples, 883944 words/s, in_qsize 8, out_qsize 3\n",
      "2020-09-28 22:52:03,625 : INFO : EPOCH 5 - PROGRESS: at 82.63% examples, 875870 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:52:04,627 : INFO : EPOCH 5 - PROGRESS: at 88.79% examples, 869716 words/s, in_qsize 10, out_qsize 5\n",
      "2020-09-28 22:52:05,629 : INFO : EPOCH 5 - PROGRESS: at 96.35% examples, 876566 words/s, in_qsize 11, out_qsize 0\n",
      "2020-09-28 22:52:06,083 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-09-28 22:52:06,089 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-09-28 22:52:06,100 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-09-28 22:52:06,102 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-09-28 22:52:06,103 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-09-28 22:52:06,107 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-09-28 22:52:06,109 : INFO : EPOCH - 5 : training on 17901873 raw words (12862066 effective words) took 14.6s, 880405 effective words/s\n",
      "2020-09-28 22:52:06,110 : INFO : training on a 89509365 raw words (64313321 effective words) took 71.3s, 901776 effective words/s\n",
      "2020-09-28 22:52:06,113 : INFO : precomputing L2-norms of word weight vectors\n",
      "2020-09-28 22:52:06,141 : INFO : saving Word2Vec object under 300features_40minwords_10context, separately None\n",
      "2020-09-28 22:52:06,142 : INFO : not storing attribute vectors_norm\n",
      "2020-09-28 22:52:06,144 : INFO : not storing attribute cum_table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-28 22:52:06,726 : INFO : saved 300features_40minwords_10context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Svaing Complete\n"
     ]
    }
   ],
   "source": [
    "# 初始化并训练模型\n",
    "print(\"Start Training model...\")\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "print(\"Training Complete\")\n",
    "\n",
    "# 保存模型以供以后使用，载入时用 Word2Vec.load()\n",
    "model_name = \"300features_40minwords_10context\" # 模型名称\n",
    "model.save(model_name)\n",
    "print(\"Svaing Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitchen\n",
      "berlin\n",
      "paris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\gensim\\models\\keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \n",
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match(\"man woman child kitchen\".split()))\n",
    "print(model.doesnt_match(\"france england germany berlin\".split()))\n",
    "print(model.doesnt_match(\"paris berlin london austria\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.6221582889556885), ('lady', 0.5844950675964355), ('lad', 0.5493677854537964), ('guy', 0.5265066623687744), ('person', 0.5254271030426025), ('farmer', 0.5244280099868774), ('millionaire', 0.5242919921875), ('soldier', 0.5171104669570923), ('monk', 0.509947657585144), ('sailor', 0.5053134560585022)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(\"man\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('edinburgh', 0.6927019357681274), ('london', 0.6783941984176636), ('venice', 0.6662055253982544), ('italy', 0.6633578538894653), ('austria', 0.6533050537109375), ('vienna', 0.6532919406890869), ('1920', 0.6511423587799072), ('1938', 0.6483134627342224), ('1953', 0.6480259895324707), ('france', 0.6431691646575928)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(\"berlin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('intriguing', 0.7502032518386841), ('entertaining', 0.6261184215545654), ('enjoyable', 0.6192778944969177), ('exciting', 0.6154883503913879), ('engaging', 0.6083738803863525), ('engrossing', 0.5933602452278137), ('fascinating', 0.5877359509468079), ('compelling', 0.5730586051940918), ('amusing', 0.5726856589317322), ('important', 0.568382203578949)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(\"interesting\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
